{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 루브릭\n",
    "---\n",
    "- 3가지 이상의 모델이 성공적으로 시도됨\n",
    "- gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 적절히 분석함\n",
    "- 네이버 영화리뷰 데이터 감성분석 정확도를 90% 이상 달성함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 준비와 확인\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3)\n",
      "(50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/project/aiffel-lms/E9_Embedding/ratings_train.txt')\n",
    "test_data = pd.read_table('~/project/aiffel-lms/E9_Embedding/ratings_test.txt')\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터로더 구성\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습때 다루었던 IMDB 데이터셋은 텍스트를 가공하여 imdb.data_loader() 메소드를 호출하면 숫자 인덱스로 변환된 텍스트와 word_to_index 딕셔너리까지 친절하게 제공합니다. 그러나 이번에 다루게 될 nsmc 데이터셋은 전혀 가공되지 않은 텍스트 파일로 이루어져 있습니다. 이것을 읽어서 imdb.data_loader()와 동일하게 동작하는 자신만의 data_loader를 만들어 보는 것으로 시작합니다. data_loader 안에서는 다음을 수행해야 합니다.\n",
    "\n",
    "- 데이터의 중복 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화\n",
    "- 불용어(Stopwords) 제거\n",
    "- 사전word_to_index 구성\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "- X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 모델구성을 위한 데이터 분석 및 가공\n",
    "---\n",
    "- 데이터셋 내 문장 길이 분포\n",
    "- 적절한 최대 문장 길이 지정\n",
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균: 15.969376315021577\n",
      "문장길이 최대: 116\n",
      "문장길이 표준편차: 12.843535456326455\n",
      "패딩문장 최대길이: 41\n",
      "전체 문장의 93.42988343341575%가 maxlen 설정 이내에 포함됩니다\n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "print('문장길이 평균:', np.mean(num_tokens))\n",
    "print('문장길이 최대:', np.max(num_tokens))\n",
    "print('문장길이 표준편차:', np.std(num_tokens))\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "\n",
    "print('패딩문장 최대길이:', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정 이내에 포함됩니다'.format(np.sum(num_tokens < max_tokens)/len(num_tokens) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n",
      "(146182,)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(X_train, value=word_to_index['<PAD>'], \n",
    "                                                    padding='pre', maxlen=maxlen)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(X_test, value=word_to_index['<PAD>'], \n",
    "                                                    padding='pre', maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 모델구성 및 validation set 구성\n",
    "---\n",
    "모델은 3가지 이상 다양하게 구성하여 실험해 보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86182, 41)\n",
      "(86182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:60000]   \n",
    "y_val = y_train[:60000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[60000:]  \n",
    "partial_y_train = y_train[60000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 328,865\n",
      "Trainable params: 328,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 32\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(32))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          3600      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 325,553\n",
      "Trainable params: 325,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 32  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model_2 = keras.Sequential()\n",
    "model_2.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_2.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model_2.add(keras.layers.MaxPooling1D(5))\n",
    "model_2.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model_2.add(keras.layers.GlobalMaxPooling1D())\n",
    "model_2.add(keras.layers.Dense(8, activation='relu'))\n",
    "model_2.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 320,273\n",
      "Trainable params: 320,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 32  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model_3 = keras.Sequential()\n",
    "model_3.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_3.add(keras.layers.GlobalMaxPooling1D())\n",
    "model_3.add(keras.layers.Dense(8, activation='relu'))\n",
    "model_3.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 모델 훈련 개시\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1347/1347 [==============================] - 8s 6ms/step - loss: 0.3994 - accuracy: 0.8178 - val_loss: 0.3465 - val_accuracy: 0.8479\n",
      "Epoch 2/5\n",
      "1347/1347 [==============================] - 8s 6ms/step - loss: 0.3170 - accuracy: 0.8635 - val_loss: 0.3421 - val_accuracy: 0.8505\n",
      "Epoch 3/5\n",
      "1347/1347 [==============================] - 7s 5ms/step - loss: 0.2768 - accuracy: 0.8816 - val_loss: 0.3381 - val_accuracy: 0.8542\n",
      "Epoch 4/5\n",
      "1347/1347 [==============================] - 7s 6ms/step - loss: 0.2407 - accuracy: 0.8987 - val_loss: 0.3496 - val_accuracy: 0.8526\n",
      "Epoch 5/5\n",
      "1347/1347 [==============================] - 8s 6ms/step - loss: 0.2113 - accuracy: 0.9125 - val_loss: 0.3805 - val_accuracy: 0.8515\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3844 - accuracy: 0.8474\n",
      "[0.38440510630607605, 0.8474479913711548]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2694/2694 [==============================] - 17s 6ms/step - loss: 0.3895 - accuracy: 0.8178 - val_loss: 0.3316 - val_accuracy: 0.8553\n",
      "Epoch 2/5\n",
      "2694/2694 [==============================] - 12s 4ms/step - loss: 0.2749 - accuracy: 0.8857 - val_loss: 0.3345 - val_accuracy: 0.8548\n",
      "Epoch 3/5\n",
      "2694/2694 [==============================] - 11s 4ms/step - loss: 0.1973 - accuracy: 0.9229 - val_loss: 0.3766 - val_accuracy: 0.8444\n",
      "Epoch 4/5\n",
      "2694/2694 [==============================] - 11s 4ms/step - loss: 0.1300 - accuracy: 0.9525 - val_loss: 0.4568 - val_accuracy: 0.8447\n",
      "Epoch 5/5\n",
      "2694/2694 [==============================] - 11s 4ms/step - loss: 0.0921 - accuracy: 0.9675 - val_loss: 0.5273 - val_accuracy: 0.8404\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_2 = model_2.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 [==============================] - 4s 3ms/step - loss: 0.5386 - accuracy: 0.8379\n",
      "[0.5386026501655579, 0.8379274606704712]\n"
     ]
    }
   ],
   "source": [
    "results = model_2.evaluate(x_test,  y_test, verbose=1)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict_2 = history_2.history\n",
    "print(history_dict_2.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1347/1347 [==============================] - 5s 4ms/step - loss: 0.4357 - accuracy: 0.8078 - val_loss: 0.3566 - val_accuracy: 0.8429\n",
      "Epoch 2/5\n",
      "1347/1347 [==============================] - 6s 4ms/step - loss: 0.3150 - accuracy: 0.8663 - val_loss: 0.3508 - val_accuracy: 0.8471\n",
      "Epoch 3/5\n",
      "1347/1347 [==============================] - 5s 4ms/step - loss: 0.2700 - accuracy: 0.8900 - val_loss: 0.3612 - val_accuracy: 0.8469\n",
      "Epoch 4/5\n",
      "1347/1347 [==============================] - 5s 4ms/step - loss: 0.2342 - accuracy: 0.9070 - val_loss: 0.3798 - val_accuracy: 0.8437\n",
      "Epoch 5/5\n",
      "1347/1347 [==============================] - 5s 3ms/step - loss: 0.2042 - accuracy: 0.9211 - val_loss: 0.4045 - val_accuracy: 0.8417\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_3 = model_3.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 1s - loss: 0.4143 - accuracy: 0.8365\n",
      "[0.41429242491722107, 0.8364627361297607]\n"
     ]
    }
   ],
   "source": [
    "results = model_3.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict_3 = history_3.history\n",
    "print(history_dict_3.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Loss, Accuracy 그래프 시각화\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 학습된 Embedding 레이어 분석\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/project/aiffel-lms/E9_Embedding/word2vec_mine.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07976415,  0.03918341,  0.01170995,  0.02844974,  0.04866054,\n",
       "       -0.00688295,  0.06125975,  0.04118128, -0.05804366, -0.00932911,\n",
       "        0.04627677,  0.06171273, -0.00800136,  0.06663141, -0.04996091,\n",
       "        0.05542096, -0.00589052,  0.13882327, -0.00888363,  0.03896485,\n",
       "        0.01152777,  0.01735454, -0.02148382,  0.03666715, -0.0522636 ,\n",
       "       -0.02198328, -0.00842652,  0.01333505, -0.09706151, -0.01080363,\n",
       "       -0.07550645, -0.04805997], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['영화']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('가치', 0.8445396423339844),\n",
       " ('.???', 0.8192390203475952),\n",
       " ('리암', 0.8046497106552124),\n",
       " ('보여요', 0.7947922945022583),\n",
       " ('레슬리', 0.7900536060333252),\n",
       " ('먹이', 0.7884384989738464),\n",
       " ('렵니다', 0.7879118919372559),\n",
       " ('신화', 0.7811463475227356),\n",
       " ('씹', 0.777438759803772),\n",
       " ('쇼킹', 0.7765204906463623)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"스릴러\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) 한국어 Word2Vec 임베딩 활용하여 성능개선\n",
    "---\n",
    "한국어 Word2Vec은 다음 경로에서 구할 수 있습니다.\n",
    "\n",
    "https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7577837  -1.0874279   1.5300866  -0.1115231  -0.37980682  1.4828517\n",
      "  1.3180419   0.11094163  0.7430535  -0.45461136  0.58841336  0.5763913\n",
      "  1.210707    1.3132795  -0.86962503 -0.18507595 -0.47440064  1.5100725\n",
      "  1.0965794   1.0600823  -0.27457932 -0.70003706  2.3117511   1.4944884\n",
      "  0.25560892 -2.866659   -0.28312334  0.34263936 -0.67723423  0.71714777\n",
      "  0.25549442  0.71732044 -0.13262457  0.01792452 -0.3184774   0.5271619\n",
      "  0.7561084  -2.1247065   1.061429   -0.21065854  0.6877343  -1.4956383\n",
      "  0.60346967 -2.6955893   0.37694618 -1.0164185   0.5430663   0.1200121\n",
      " -2.6315718   0.6216742   1.1583976  -2.5385962   1.326312   -0.10284371\n",
      " -0.0286147  -0.9132947   0.7647564   0.79202783 -1.8625957  -0.7418395\n",
      "  0.5884277  -0.9917992  -0.62114453  1.5367815  -0.6628939   0.6712103\n",
      "  0.12914915  0.21228492  0.9017655  -0.25083402  0.71500814  0.08644514\n",
      "  0.59993285  0.5766137   0.64095974  0.47888306 -2.8426213  -2.8502681\n",
      " -0.140544   -1.5917364   0.26691505  0.59476066  0.85868204  1.0322351\n",
      "  0.25671318 -0.34831643  1.752927   -0.21967097 -0.77352476  1.6995213\n",
      "  1.3996491  -0.9419836   0.85996443 -1.8812876  -2.5428605   0.39351937\n",
      " -1.2882805   0.56548136  1.006273    1.2217585   3.5744793   1.717737\n",
      "  1.6917158  -2.2176905  -0.3167447   1.2449     -1.255284   -2.1539652\n",
      " -1.096709   -0.74976933 -0.16744931 -1.8507233   2.1861036  -0.05389732\n",
      "  1.038033    0.33730686 -1.4647075  -1.264041    0.25509247  0.0622906\n",
      "  0.27852032 -0.52661455  0.8529616   0.58257025 -0.57665855  1.3990631\n",
      "  0.28237963  1.6566037   1.9912103   0.63888913  0.7732426  -1.3757724\n",
      "  0.17209321 -0.2433672   0.6328291   1.486971    2.3435354  -1.7037928\n",
      "  3.1944559  -1.9049606  -0.51309574  0.79082954 -1.4480313  -0.68631476\n",
      "  0.62008876 -2.3400223  -0.5785594   0.5270694   3.0061607  -1.3661511\n",
      " -2.7953272  -1.1794031  -0.27734265  0.71130925 -0.06620383  0.33663416\n",
      "  0.7204997  -0.923218   -2.1603265  -0.8904896  -1.4137112  -0.4189144\n",
      "  0.42834592  1.8104875  -1.8274456  -0.26700613  0.7743727   0.80048114\n",
      "  1.1333636   3.2746978  -0.0188297   0.9245737  -0.1246058  -0.5802861\n",
      " -0.01926111  1.05892    -1.4247856   1.0689156   2.5728712  -1.294882\n",
      "  0.74771804  1.3066916  -1.3213431   1.6501019  -0.12401557  0.96340084\n",
      "  0.26050946  1.3826336  -0.02877662  2.3431563  -0.26337367  1.9162012\n",
      " -0.77454543  1.7392642   0.08038983 -0.60325927  0.29508227  0.4812675\n",
      "  0.5271086   0.94171894]\n",
      "[('영화화하', 0.730082094669342), ('로맨스', 0.6989323496818542), ('코미디', 0.6905182600021362), ('로맨틱', 0.6693053245544434), ('다큐멘터리', 0.6563485264778137), ('영화', 0.6533163785934448), ('히치콕', 0.6332706212997437), ('무협', 0.6284650564193726), ('장편', 0.6283017992973328), ('미스터리', 0.6273175477981567)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/project/aiffel-lms/E9_Embedding/data/ko.bin'\n",
    "word2vec = gensim.models.Word2Vec.load(word2vec_path)\n",
    "\n",
    "vector = word2vec['영화']\n",
    "print(vector)\n",
    "\n",
    "result = word2vec.wv.most_similar(\"스릴러\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,168,577\n",
      "Trainable params: 2,168,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1347/1347 [==============================] - 22s 16ms/step - loss: 0.4098 - accuracy: 0.8101 - val_loss: 0.3468 - val_accuracy: 0.8496\n",
      "Epoch 2/10\n",
      "1347/1347 [==============================] - 21s 16ms/step - loss: 0.2968 - accuracy: 0.8742 - val_loss: 0.3198 - val_accuracy: 0.8627\n",
      "Epoch 3/10\n",
      "1347/1347 [==============================] - 21s 16ms/step - loss: 0.2466 - accuracy: 0.8980 - val_loss: 0.3269 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "1347/1347 [==============================] - 22s 16ms/step - loss: 0.1988 - accuracy: 0.9203 - val_loss: 0.3595 - val_accuracy: 0.8607\n",
      "Epoch 5/10\n",
      "1347/1347 [==============================] - 22s 16ms/step - loss: 0.1550 - accuracy: 0.9399 - val_loss: 0.3691 - val_accuracy: 0.8597\n",
      "Epoch 6/10\n",
      "1347/1347 [==============================] - 21s 15ms/step - loss: 0.1140 - accuracy: 0.9578 - val_loss: 0.4542 - val_accuracy: 0.8532\n",
      "Epoch 7/10\n",
      "1347/1347 [==============================] - 21s 15ms/step - loss: 0.0820 - accuracy: 0.9701 - val_loss: 0.5015 - val_accuracy: 0.8540\n",
      "Epoch 8/10\n",
      "1347/1347 [==============================] - 21s 16ms/step - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.5944 - val_accuracy: 0.8510\n",
      "Epoch 9/10\n",
      "1347/1347 [==============================] - 21s 16ms/step - loss: 0.0483 - accuracy: 0.9831 - val_loss: 0.6545 - val_accuracy: 0.8496\n",
      "Epoch 10/10\n",
      "1347/1347 [==============================] - 22s 16ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 0.7193 - val_accuracy: 0.8522\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.7142 - accuracy: 0.8524\n",
      "[0.714198887348175, 0.852350652217865]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting\n",
    "---\n",
    "아무리 파라미터를 바꾸어봐도 val_accuracy가 학습에 따라 개선되지 않고 큰 차이가 없거나 오히려 떨어지는 모습을 보였는데 왜 그런지 알 수가 없었습니다....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
